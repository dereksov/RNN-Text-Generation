{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-F1gVLMRypy"
   },
   "source": [
    "#RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7zFXxTUR3FX"
   },
   "source": [
    "##import/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33771,
     "status": "ok",
     "timestamp": 1608316790424,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "DVWgO7dKCi5-",
    "outputId": "96fc5f9b-616d-45fd-d223-6efb64fc5c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 33763,
     "status": "ok",
     "timestamp": 1608316790425,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "DyJBV58ISmh7"
   },
   "outputs": [],
   "source": [
    "#path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "#text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "#print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34177,
     "status": "ok",
     "timestamp": 1608316790847,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "9oncwfshGzJr",
    "outputId": "f0361df2-67aa-41f6-ebac-e6129ffec188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 3381928 characters\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/My Drive/sherlock.txt', 'r') as f: \n",
    "    text = f.read()\n",
    "\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34170,
     "status": "ok",
     "timestamp": 1608316790848,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "KdQ9zz8AHd3L",
    "outputId": "1980f3df-e922-4985-b96c-6a8dab0de695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "                          THE COMPLETE SHERLOCK HOLMES\n",
      "\n",
      "                               Arthur Conan Doyle\n",
      "\n",
      "\n",
      "\n",
      "                                Table of contents\n",
      "\n",
      "               A Study In Scarlet\n",
      "\n",
      "               The Sign of the Four\n",
      "\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZfnqbEtR6X8"
   },
   "source": [
    "##vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34566,
     "status": "ok",
     "timestamp": 1608316791252,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "U9fNp3EgHgFW",
    "outputId": "25435f7c-1f4b-40cd-b274-a5e1637afb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters\n",
    "vocab = sorted(set(text))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 34809,
     "status": "ok",
     "timestamp": 1608316791501,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "X-ri52vDH0kn"
   },
   "outputs": [],
   "source": [
    "# map unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34803,
     "status": "ok",
     "timestamp": 1608316791501,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "_p0is-_ZH2Zx",
    "outputId": "b1e6f032-cabc-4602-d14e-4a290542a305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  '*' :   8,\n",
      "  ',' :   9,\n",
      "  '-' :  10,\n",
      "  '.' :  11,\n",
      "  '/' :  12,\n",
      "  '0' :  13,\n",
      "  '1' :  14,\n",
      "  '2' :  15,\n",
      "  '3' :  16,\n",
      "  '4' :  17,\n",
      "  '5' :  18,\n",
      "  '6' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34798,
     "status": "ok",
     "timestamp": 1608316791502,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "gFDvvboPdXt8",
    "outputId": "50471a0d-41d6-4490-a90a-6dc1e8710ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n\\n\\n\\n         ' ---- characters mapped to int ---- > [0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40469,
     "status": "ok",
     "timestamp": 1608316797178,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "rfjoluxJdZ-r",
    "outputId": "aadf6699-b16e-42d6-856e-83e769eb71e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40465,
     "status": "ok",
     "timestamp": 1608316797180,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "ukdGmSpcdcFy",
    "outputId": "4851ef96-3a42-4769-e5f0-7e0ffea613ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n\\n\\n\\n                          THE COMPLETE SHERLOCK HOLMES\\n\\n                               Arthur Con'\n",
      "'an Doyle\\n\\n\\n\\n                                Table of contents\\n\\n               A Study In Scarlet\\n\\n   '\n",
      "'            The Sign of the Four\\n\\n                  The Adventures of Sherlock Holmes\\n               '\n",
      "'A Scandal in Bohemia\\n               The Red-Headed League\\n               A Case of Identity\\n         '\n",
      "'      The Boscombe Valley Mystery\\n               The Five Orange Pips\\n               The Man with the'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 40461,
     "status": "ok",
     "timestamp": 1608316797181,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "Nrv2nDxeddyv"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40457,
     "status": "ok",
     "timestamp": 1608316797181,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "1RrIn4Y7dgkF",
    "outputId": "3bbafae3-634c-442e-cd69-50752ad1a9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '\\n\\n\\n\\n                          THE COMPLETE SHERLOCK HOLMES\\n\\n                               Arthur Co'\n",
      "Target data: '\\n\\n\\n                          THE COMPLETE SHERLOCK HOLMES\\n\\n                               Arthur Con'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40453,
     "status": "ok",
     "timestamp": 1608316797182,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "h8AYLbaddhz9",
    "outputId": "90b7acd8-2066-4a81-f0ee-a2d941df7e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 0 ('\\n')\n",
      "Step    1\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 0 ('\\n')\n",
      "Step    2\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 0 ('\\n')\n",
      "Step    3\n",
      "  input: 0 ('\\n')\n",
      "  expected output: 1 (' ')\n",
      "Step    4\n",
      "  input: 1 (' ')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SikPIxwSHx1"
   },
   "source": [
    "##base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40447,
     "status": "ok",
     "timestamp": 1608316797182,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "dxI8jRVQdjdB",
    "outputId": "018f465e-7c03-40f8-abdc-5037f1139790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 40443,
     "status": "ok",
     "timestamp": 1608316797182,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "HWZ9ieSndoLo"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 40867,
     "status": "ok",
     "timestamp": 1608316797609,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "IX02ToMKdtdE"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 40864,
     "status": "ok",
     "timestamp": 1608316797609,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "DczJkJbcdu5q"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48332,
     "status": "ok",
     "timestamp": 1608316805083,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "a2pKuAiZdv6I",
    "outputId": "98600f95-2263-47cf-8db3-39d63782e319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 97) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48328,
     "status": "ok",
     "timestamp": 1608316805084,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "GDxbx2xOdxXu",
    "outputId": "d111a41a-8fc6-49d6-bd9b-c333b03f16d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 48324,
     "status": "ok",
     "timestamp": 1608316805084,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "8pg-gXMadzlQ"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48318,
     "status": "ok",
     "timestamp": 1608316805084,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "bM-or8k5d1H-",
    "outputId": "f89b8ad6-ea71-4004-99ae-27bf2a6f3e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ruded out of the floor. Then it was withdrawn as\\n     suddenly as it appeared, and all was dark agai'\n",
      "\n",
      "Next Char Predictions: \n",
      " '65ñKP\\'o;;kOüP.96mFEs:àRi’3!/`LñâHLN7ôgkq[\"lB6733:9N8zo]x£7.3M]vzTnxCCKK j`S?4dt½nCQîq`UûfyülséTYß,à&'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48314,
     "status": "ok",
     "timestamp": 1608316805085,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "FXjOHEQnd2Yy",
    "outputId": "52d178d4-72eb-449c-d86d-948578b410cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 97)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.5767837\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 48309,
     "status": "ok",
     "timestamp": 1608316805085,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "dPmHG4FQd4_M"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDUIeZuvSVYN"
   },
   "source": [
    "## epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 48307,
     "status": "ok",
     "timestamp": 1608316805086,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "aTxOS2aud6vp"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 48305,
     "status": "ok",
     "timestamp": 1608316805087,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "jg2MtVQZd8CV"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374143,
     "status": "ok",
     "timestamp": 1608317130930,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "UF0uejEWd9QO",
    "outputId": "0ad97858-dd39-4692-a313-81c8682359d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "523/523 [==============================] - 33s 58ms/step - loss: 2.6100\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4129\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.2427\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1735\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1310\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0966\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0707\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0492\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0277\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0096\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 374140,
     "status": "ok",
     "timestamp": 1608317130932,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "0uKZU0nLd-T8",
    "outputId": "7de31a39-4bd7-4302-c1d4-a143cbe05e7d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'./training_checkpoints/ckpt_10'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 374356,
     "status": "ok",
     "timestamp": 1608317131154,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "aifD6USVeWzl"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374352,
     "status": "ok",
     "timestamp": 1608317131155,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "xwOUPT4veYZh",
    "outputId": "88b69419-4295-4b56-bd57-e32059e57263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjxQPB6fSZ_I"
   },
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 374348,
     "status": "ok",
     "timestamp": 1608317131155,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "7SUp5OUPeZVY"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378793,
     "status": "ok",
     "timestamp": 1608317135606,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "aeYbBQiNedeT",
    "outputId": "57437f2e-7bf1-4c67-be1a-b72a3aa70b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock headed is\n",
      "     descended, and with a sailor country building and face he feads\n",
      "     an emergen land, they would seize up a juncof it once more to ask, when I had\n",
      "     readily in it, impenefally used as his body ladiments considerably wealthy the\n",
      "     gentleman. I human with this point would be to extreord. They\n",
      "     talk efore old dream--such as turning two\n",
      "     eyes, practical spocial towards us--\"\n",
      "\n",
      "     Holmes toicess with this hiding-place.\n",
      "\n",
      "     \"They have glared the advice. His dressing-room\n",
      "     gave no scowling glancing that he could accept a little for the\n",
      "     nt was but him.\"\n",
      "\n",
      "     \"Then we bead like the essentials of what you don't know that there\n",
      "     was down An electround if you can send your brain to CurKh\n",
      "\n",
      "     The Croweral Square. Amus add the words of the edge of something fect. His face\n",
      "     still was unlikely to him there. Holmes give\n",
      "     you all in which my mele rattle how you would be more. They\n",
      "     struck home leaving with a real murder at the world, and would \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Sherlock \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383404,
     "status": "ok",
     "timestamp": 1608317140225,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "CncZJLOQeelA",
    "outputId": "85256b57-bd3a-4cd7-9f07-9edf60d8657b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we\n",
      "     have fred on accounts to her rugge and second\n",
      "     projecting designs the galloys of finding the daily\n",
      "     damp-backed door, and heavily beyond one of this evil murder.\n",
      "\n",
      "     \"I can see d.\" He did somehow all three seemed across the retirns that I\n",
      "     had let the uge of traceid Inly deceives the agent\n",
      "     disappointed. The clergyman, but within our man, with a\n",
      "     cabable in his rooms.\"\n",
      "\n",
      "     The bbother had become expecially, once or no--orgeon the moor.\n",
      "     Here we have decayed so we now, and Godfrey was to be despair. I shall guide\n",
      "     three inclusive residence in the friends beside by the short and\n",
      "     sallowly dropping rapidly. A shadow was close to the burotest\n",
      "     face\n",
      "     himself which I have not\n",
      "     learned to show you have help out in my direction without the suspicion, the towns\n",
      "     which led to the lid. And me under the lady. \"Ah, yes--the fatal effort. We caught one\n",
      "     of the event for me to the lawy, and in reading the hat\n",
      "     you wore a migst of it\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"When\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388184,
     "status": "ok",
     "timestamp": 1608317145011,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "Uu4KCUKYe46x",
    "outputId": "7fc1236f-2f98-445d-f739-813b910d44ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovering with\n",
      "     admiration, and had once beced the teral to\n",
      "     leave, then! that surly it all, played these, were removed young man, with\n",
      "     McMurdo and a badx on earth to get round to it will be back by reward to chord. Mycroft, it is true, too! I thought your motive cannot be more. After all.\n",
      "     But the front, silver, taking that Willable sheer best had rung-ink.\n",
      "\n",
      "     \"It is losely that we may not go so hard when they were leaving to us. There is\n",
      "     any in their smiling as he replaced it therence. May I ask.\n",
      "     Sherlock Hallshires had been kissed in has a connection with\n",
      "     the wind-wood of the room, and mack before we would be taken, and\n",
      "     made frame of him, Miss Stapleton had books immissive\n",
      "     o'clock. We are greatly at the time later mad over to it. You know me. What's this, it's\n",
      "     question has not disappeared.\"\n",
      "\n",
      "     \"What was it?\" asked Holmes.\n",
      "\n",
      "     \"Why, you are jointed out some trade!\"\n",
      "\n",
      "     \"Yes, it was a door that I'll shafe that her solution come oncome\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"discover\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxoAWK6zSeGE"
   },
   "source": [
    "## functionize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 388180,
     "status": "ok",
     "timestamp": 1608317145011,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "2mx4Q8lpfSb8"
   },
   "outputs": [],
   "source": [
    "def iteration(embed_dim,rnn_units,epochs):\n",
    "  dataset = sequences.map(split_input_target)\n",
    "  dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "  vocab_size = len(vocab)\n",
    "  embedding_dim = embed_dim\n",
    "  rnn_units = rnn_units\n",
    "\n",
    "  model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "  checkpoint_dir = './training_checkpoints'\n",
    "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_prefix,\n",
    "      save_weights_only=True)\n",
    "\n",
    "  history = model.fit(dataset, epochs=epochs, callbacks=[checkpoint_callback])\n",
    "\n",
    "  tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "  print(\"\\n---\\n\")\n",
    "\n",
    "  model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "  model.load_weights(tf.train.latest_checkpoint(checkpoint_dir)).expect_partial()\n",
    "\n",
    "  model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  print(generate_text(model, start_string=u\"Sherlock\"))\n",
    "\n",
    "  print(\"\\n---\\n\")\n",
    "\n",
    "  print(generate_text(model, start_string=u\"When\"))\n",
    "\n",
    "  print(\"\\n---\\n\")\n",
    "\n",
    "  print(generate_text(model, start_string=u\"discover\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ermaMw1_ODex"
   },
   "source": [
    "#RNN Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVceUpqzRCea"
   },
   "source": [
    "## 256 512 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 560545,
     "status": "ok",
     "timestamp": 1608317317381,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "gzjch8pFjuGe",
    "outputId": "97371269-e327-4b6f-9efa-441bef35729c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (64, None, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 97)            49761     \n",
      "=================================================================\n",
      "Total params: 1,257,313\n",
      "Trainable params: 1,257,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 17s 28ms/step - loss: 2.6967\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.5412\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.3411\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.2577\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.2126\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.1818\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.1589\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.1408\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.1258\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 16s 28ms/step - loss: 1.1107\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 512)            1182720   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 97)             49761     \n",
      "=================================================================\n",
      "Total params: 1,257,313\n",
      "Trainable params: 1,257,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes' will, Watson--that a\n",
      "     strangers done-blood-stapleton at the windows. The fudge-born\n",
      "     spoke of given as I kept it acresion. Holmes started it up and informing that the plainers\n",
      "     simpling with violence in connection; and it was as a coming necessary which may have been a view of the Scowr.\n",
      "\n",
      "     \"And it is one bearded.\"\n",
      "\n",
      "     I never seen its deval and six official, because\n",
      "     lost in panting steps gow of interest, and as I am not in notacation of the manager? If yet are indifficiated from every mischief true. She, to me, and I have\n",
      "     rolled and left him esbable, for he glamed it had begun to prove to be drawn\n",
      "     his wife. In helpbanded herself\n",
      "     who intended to have said that it is under reprogreutiously important ve\n",
      "     because at the district. To live at all it is usual, but one age your\n",
      "     objects fell into the first-thoughts. That night he whispered over his hands over with her room\n",
      "     downstation. It seems for a deepies of the\n",
      "     credital clerm\n",
      "\n",
      "---\n",
      "\n",
      "When Well, I\n",
      "     was avert as ever I came done, sometriation, for four owner had left us Green gun, but of later he\n",
      "     could only one took our dimal, absoluble succeeded,\n",
      "     which we had already held it to move a wound\n",
      "     when she had admired. To lose\n",
      "     the room before he had to strike me that they\n",
      "     but the master who share had really moved. I could help me for the plans\n",
      "     adortation twenty sick before during this case.\"\n",
      "\n",
      "     \"Didn't he have told of the plant of the hall, I find,\" he remarked. \"How would escape, it is most\n",
      "     so the grashing figure who is a very Smith, have\n",
      "     been the law, Ettie. There is a bushy father.\"\n",
      "\n",
      "     \"It is asquitch,\" said jy you.\"\n",
      "\n",
      "     We are equally between practing the place where the maids, and it\n",
      "     clay upon the stair, and it was fresh had been afford; the second lenth\n",
      "     may surkoncess. What in the word,\" he cried. \"The son, I shall be\n",
      "     nearther. You are abdoking in that taste, passed loose at the tundrist. I suppose\n",
      "     y\n",
      "\n",
      "---\n",
      "\n",
      "discover-manners and that he was\n",
      "     doing already somewhere aboard would have lost if o good\n",
      "     theorse barondon together, for I was\n",
      "     bussing at it, but with his own shrew cigarette\n",
      "     West Lucastle other. It is at the absence.\"\n",
      "\n",
      "     I long reconstructing his chinnimsyifican had continued forlow. They found my mind, saw\n",
      "     Carruthoss times-girl that upper very late announced it.\"\n",
      "\n",
      "     \"You have suggested. The husband may find them all cleared beyonded my-point.\" He looked round\n",
      "     the hotel order-remarkable. He waited in one of Hitto time the snight, having a tall\n",
      "     \" The deatewas\n",
      "     counted face in the young man. \"This word would not\n",
      "     imagine where the women touched it. The door upon his hand, his\n",
      "     eyes upon the case shoen? Thank you, Sir-JJE72àTI\n",
      "     Mary Muser's gallament was already book through the door when you\n",
      "     say our jeck. \"I have got his words yet there was no importance of\n",
      "     Parisnow, did the pursuat, so arene of the most short when he find a lwa\n"
     ]
    }
   ],
   "source": [
    "iteration(256,512,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv_v0LtGRHg3"
   },
   "source": [
    "##256 256 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 679459,
     "status": "ok",
     "timestamp": 1608317436301,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "LYbEInzTk8dY",
    "outputId": "86ce02bd-57ae-4f7b-86f4-44a464fbab9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (64, None, 256)           394752    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 97)            24929     \n",
      "=================================================================\n",
      "Total params: 444,513\n",
      "Trainable params: 444,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 12s 18ms/step - loss: 2.5659\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.5750\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.4061\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.3330\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.2904\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.2630\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 11s 19ms/step - loss: 1.2422\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 10s 17ms/step - loss: 1.2276\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.2141\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 10s 18ms/step - loss: 1.2058\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 256)            394752    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 97)             24929     \n",
      "=================================================================\n",
      "Total params: 444,513\n",
      "Trainable params: 444,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes, that Mr. Fortany\n",
      "     complicat of my clothes, safe. James Ruschbeau,\n",
      "     putt us about the horicial, and it wouldered uproad.\n",
      "\n",
      "     \"And heed the lodge; Lest I am paid, that there could had all\n",
      "     taken them to get the Poictor,\n",
      "     Watson, what you possibly be dead more pursual to our serief once.\"\n",
      "\n",
      "     \"Any sofa. He ran here a ser  message the ricent man, and presuming bad to dark for a most tiously runcy.\"\n",
      "\n",
      "     It called mine.3 Counterry Bover your wrisk,\n",
      "     and a friend I should one in the clatter danger, in the edge of our\n",
      "     left on the ring.\"\n",
      "\n",
      "     \"'It was surling our valusion, looking was stralk out of your\n",
      "     cloud on a bicycle lonely into Pontry? There were more blacker's wiser\n",
      "     above them. If dismidaked thusmisthelf. We have had the Sholto\n",
      "     Pennister satisf,\n",
      "     and be near the war--after his business the long of the feet, under excitable.\n",
      "     On a smile, no have been anything much follower, and set d a complete horself of farm Case, I hear\n",
      "  \n",
      "\n",
      "---\n",
      "\n",
      "Whent to my sofa\n",
      "\n",
      "\n",
      "     Cock, and I will have no concerned. From the erbinappation of\n",
      "     Wilson specialitle it about?\"\n",
      "\n",
      "     \"I am the desprided and nerves be passed of written his charbes, and that I went to me, and so are we sake\n",
      "     to pulils with the deed, interview, but I will cat together, she does not 'all. \"What was that of\n",
      "     time to Watson,\" said he can't possitience that that swinf of the\n",
      "     British to ifation, if there was no afud taking an hands of years for ourselves. It was the time,  after\n",
      "     that morning. I had, my dear Wating ghable, or fail to\n",
      "     hear peace--socter.\"\n",
      "\n",
      "     \"That is it?\"\n",
      "\n",
      "     The busy of Harible before you next picked a serious curbards which is! Holmes went to discovering from the\n",
      "     feet. \"The grape had never almeak where there are no prpara, and\n",
      "     there are a names occurrens.\"\n",
      "\n",
      "     \"And the Paxement was retrean Milverton Hampsurould\n",
      "     part on my hours, then?\"\n",
      "\n",
      "     Our vigarrs), McMurdo should fallen back what you should I never at\n",
      "\n",
      "---\n",
      "\n",
      "discover, or how contaired\n",
      "     the good duries's aviable marks of bill. A heart of a\n",
      "     black   Agein'd Here of billiard curtu, Rucclain when save you to an old boy suddenly to\n",
      "     be down. I took us before this teleggage and own heart. I wouldn't broke a remarked at the Ross\n",
      "     and nor an eyes. Holmes rose to what you are heard with or behind be\n",
      "     her in me to face. The same hair. \"Well, if I have\n",
      "     visit to be horribles which he stanging! Then had pathed after the treasure followed a\n",
      "     father and was, but what your possible\n",
      "     facts, I can't imong,\n",
      "     with me with an extraora Cusim Lord Harrest of that Blishing man, where a\n",
      "     ediered his colour of rest, suggested for us. You\n",
      "     are for this ironever, and ticking. That's bo I went by the opinion. The\n",
      "     convince crime, then BodymaVue!\" said Miss Charless, that justions but our\n",
      "     thing whit it is from the great family seemed to read if it's long lest\n",
      "     \"Tell me that I\n",
      "     found all the threw of I heard them. I \n"
     ]
    }
   ],
   "source": [
    "iteration(256,256,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0v5AgwWRKwe"
   },
   "source": [
    "##256 128 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 783553,
     "status": "ok",
     "timestamp": 1608317540401,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "p5aE2BpIxALl",
    "outputId": "c21de51c-e634-4103-e352-a5f6d920a2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (64, None, 128)           148224    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (64, None, 97)            12513     \n",
      "=================================================================\n",
      "Total params: 185,569\n",
      "Trainable params: 185,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 10s 16ms/step - loss: 2.6971\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.6935\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.5386\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.4651\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.4229\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.3972\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.3776\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.3620\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.3491\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 9s 15ms/step - loss: 1.3407\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (1, None, 128)            148224    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (1, None, 97)             12513     \n",
      "=================================================================\n",
      "Total params: 185,569\n",
      "Trainable params: 185,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlockery, who are \"\n",
      "\n",
      "     \"Nover, they comeard her eive he groan, the pockety have a bado.\"\n",
      "\n",
      "     Holmes's defingable\n",
      "     armered bulks, the swept up the commisbusony lawn Lucable fact back of far acident and dins the namitor, observing\n",
      "     he was broadastle, of it a juke,\n",
      "     and much bealwards or together, and Borked that if I twound. \"I could get the chacked no. Lerice me for\"\n",
      "     you admit my\n",
      "     away his ix Iblarse.\"\n",
      "\n",
      "     \"Then?\"\n",
      "\n",
      "     It was to\n",
      "     the more with a coill, who reterns, but it is stick-ledg ups was closed volumper.\n",
      "     In the knitiner.\n",
      "\n",
      "     \"There's the room which was need before back to me a time--\"\n",
      "\n",
      "     \"Then we insident my fire me.\"\n",
      "\n",
      "     \"Tell me smotted at Mrs. Bletch's cled out grasped talk bound--rosese mork our in Bestiving of with my covicul-place my very's's an as Pachpat into the gate, however, whose missing in him. Finded a commaster;\n",
      "     Sherlock Holmes was absolitant of the firm of mystenly always nar friends. How evening of an\n",
      "     about minute \n",
      "\n",
      "---\n",
      "\n",
      "When miles wind weak of the miss,\" said Sould's Pecurpase acknday.\n",
      "\n",
      "     \"Whone put determed the.\n",
      "     They might seemed that regaltims lady,\" he said this, patpers. But, sooningarl,\n",
      "     some\n",
      "     presuravoura of\n",
      "     incidered and\n",
      "     coiar really to me to murg a consey with a tratch--anly, and,\n",
      "     which artsmeavina third.\"\n",
      "\n",
      "     \"And that Armanicys of the life, happed in, we are\n",
      "     to by my swifts of which he take a south. This ged shry, day.\n",
      "     Hook jo, that the fird, Mr. McCarragared taken\n",
      "     do novedy day what is his blaund upon seen with\n",
      "     exeast of the talg, arvour. The other comert that, one of which seen they caunderant,\" he\n",
      "     would I\n",
      "     could not wrong. It is obviouss and heeling to next\n",
      "     what on:\n",
      "     Lestrade, must not less them and\n",
      "     wingies that occurred mes, have as se into the Godedge anything at the Fares the morning again Morany to be all us. The man laughed and lived over the gut upon their light, from they will should get at streng\n",
      "     shair we\n",
      "\n",
      "---\n",
      "\n",
      "discoveress who is what had dist.\"\n",
      "\n",
      "     \"The pull of you in the in the popice at no foger of the appearned. I only to me in one\n",
      "     rest for nothed--you befing in his promises of his pracess of it was\n",
      "     against reforea, but I remork.\"\n",
      "\n",
      "     \"I could glieved done with\n",
      "     all\n",
      "     we sun whose\n",
      "     but as could give them by accountham given\n",
      "     the use to the loudled amade-earry.\"\n",
      "\n",
      "     \"And his strong were back into the vand mornims that was a by no, Mr. Moriarry to murder with her up to\n",
      "     the dirached over the small resignality, and that twown sitting\n",
      "     two endsward referace, Didge?\"\n",
      "\n",
      "     \"One-dies from had--\"\n",
      "\n",
      "     The marderally upon\n",
      "     the\n",
      "     prusesshall, and to until the end in the corner strange suter lott?\"\n",
      "\n",
      "     \"No one of the man.\"\n",
      "\n",
      "     \"You topuce line'serves is tracer as yet me that when\n",
      "     I\n",
      "     thought him. You say py:\n",
      "\n",
      "     \"Bay Smified and refored to me. Jomeman nor Tone obciguel to advanced. I said him. I will down for run friend's is the\n",
      "     one, wimesse\n"
     ]
    }
   ],
   "source": [
    "iteration(256,128,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8eMOkOVRO7S"
   },
   "source": [
    "##256 64 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882208,
     "status": "ok",
     "timestamp": 1608317639061,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "me5-Kz3_6wD8",
    "outputId": "25b47530-39be-462a-a4e4-a465936d4a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (64, None, 64)            61824     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (64, None, 97)            6305      \n",
      "=================================================================\n",
      "Total params: 92,961\n",
      "Trainable params: 92,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 10s 15ms/step - loss: 2.8922\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.8443\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.6884\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.6202\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.5789\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.5520\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.5341\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.5189\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.5063\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 8s 14ms/step - loss: 1.4983\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (1, None, 64)             61824     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (1, None, 97)             6305      \n",
      "=================================================================\n",
      "Total params: 92,961\n",
      "Trainable params: 92,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock!\"\n",
      "\n",
      "       per, sime, and\n",
      "     with them,\" caud with mark's implaterar, anythe are day exampacede.\"\n",
      "\n",
      "     \"It a write as the part that I grot trect instand ad her die\"seobin of the left is fach\n",
      "     tell that I salkical cams. The man towan?\"\n",
      "\n",
      "          this whacter is your Wear\n",
      "     with a ways.\"\n",
      "\n",
      "     \"Weninghor Morth had thrice was for the corress gone little stud with a mon the morninghace; but you that etteres and not dondy for\n",
      "     what he was a finshed dought we have in Boscerun\n",
      "     wit me at there's the wayg to\n",
      "     ourse upon this this why strience.\" He had hardly examinelt your derive my coldend three it at a\n",
      "     you're a brought Stark, if     \"But Hoirson in the cloring that this druntlatered of abremation boin. There of the\n",
      "     why I had meeth that the trim! He had sat eachor was a man in had await in.\n",
      "\n",
      "     \"It bruct, in you had been to her grain is we a abouns.\" He was troused it on twione that thes its, and a bleen, handable Condrage. \"But I shouse secret thratied for \n",
      "\n",
      "---\n",
      "\n",
      "When Lest?\" erom reapic case areary canded is adder.\"\n",
      "\n",
      "     \"Mainsnide thas I like convorlaned lay fall lighted minute\n",
      "     ponself upon a lodent manious in strange explantch intamaning to me at the reasignal of his ondle, like answerly a\n",
      "     undergies Path as, and it place sure, and the hight.\"\n",
      "\n",
      "     \"No name\n",
      "     the prone would be\n",
      "     combared--these,\" Hisend I coninalthen was was befidly and all, to be at the find to have buld man to did to.\n",
      "\n",
      "     Tens the own with some from the possepp.\"\n",
      "\n",
      "     \"He was the lasher not for of the own deaded to gever.\"\n",
      "\n",
      "     \"Tilecter, worst\n",
      "     lenged, for to which\n",
      "     not deatuaning.\"\n",
      "\n",
      "     \"You here. When it.\" Eurest off the cloor mosting-thought.\"\n",
      "\n",
      "     \"The neat upon the one it.\"\n",
      "\n",
      "     \"'That have let migh there beside converignst, is\n",
      "     know nall conlessed. That was bush lost. If he fronds, and so nevine. A very that my windowst the portrenes.\n",
      "     What lay remarkselfed Stranced from Palled of hell do dierse little smight rubs\n",
      "     unongs, thi\n",
      "\n",
      "---\n",
      "\n",
      "discovering a mon the Natfleds, from presences what beyonf\n",
      "     I could name.  \"They,\" I cold. \"I complaching most live heard the wit whelands of\n",
      "     did come about figging murdered the masty-can searer of ever for so last instantly have hour the Chort. \"It leg.\n",
      "\n",
      "     \"\n",
      "\n",
      "     \"Jokng?\" I have there. Alother\n",
      "     deap and him mon a house way in it would\n",
      "     the may weich must haired to seemed\n",
      "     not het, and jare, and seything a shall this\n",
      "     taken plare. On them fecture was paper y ut upon the from the hudding flool colfce at anything man\n",
      "     that you have cooy Lemarkflenicgole, that we wame had greep, the opening one presenched the spges.\n",
      "\n",
      "     \"You have us here on the door and I re or the one of greas's looked at the whole when Spers his minuteals the dince chaition when he neterce?\n",
      "\n",
      "     the man?\"\n",
      "\n",
      "     \"Do. I must before where Black for his there faid betwes, and while the placed, pooral, may costy leave\n",
      "     made eove desess of at it eorramy.\"\n",
      "\n",
      "     \"Perking must bread arat the exer\n"
     ]
    }
   ],
   "source": [
    "iteration(256,64,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RGeJfOtOMCJ"
   },
   "source": [
    "#Embed Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFDBfHl9RbZc"
   },
   "source": [
    "##64 1024 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180734,
     "status": "ok",
     "timestamp": 1608317937593,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "GlDLCUxQPPZZ",
    "outputId": "33ff0d93-f738-4a43-b0ad-bf6c8245323c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (64, None, 64)            6208      \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (64, None, 1024)          3348480   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 3,454,113\n",
      "Trainable params: 3,454,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 28s 50ms/step - loss: 2.7950\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 27s 50ms/step - loss: 1.5539\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 28s 52ms/step - loss: 1.3100\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 28s 52ms/step - loss: 1.2155\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 28s 52ms/step - loss: 1.1625\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 29s 53ms/step - loss: 1.1243\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 29s 53ms/step - loss: 1.0949\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 29s 53ms/step - loss: 1.0701\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 29s 53ms/step - loss: 1.0474\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 29s 53ms/step - loss: 1.0268\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (1, None, 64)             6208      \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (1, None, 1024)           3348480   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 3,454,113\n",
      "Trainable params: 3,454,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes was all dazided.\n",
      "     Keen you'segious and only the one in the world; but, as I have no\n",
      "     drand.\n",
      "\n",
      "     \"I am possible that I had lit from the darkness sey of his cases which have ever\n",
      "     observed. I sent the window, lay down here to\n",
      "     uneash. No doubt,\" said Holmes.\n",
      "\n",
      "     \"Colonel Moran      crust remains across the country.\n",
      "\n",
      "     \"There't Thempthere will be in England. Garia, McMurdo, so I know,\n",
      "     Certainly, if my ith to man that nothing that they had\n",
      "     ly met. There was bare enough on the moor. And\n",
      "     let us veriferious the envelope which passed fifty face, I saw him from hearth\n",
      "     to occasion. It is a question. You show you a chance, nor would come\n",
      "     training. By Garcial, and that you say? ]\n",
      ",     care him. Hisly, and its necessary reservations, the\n",
      "     scyool-dogs gave an absurd linkles of course, in dounly up, I know where my highriding is mistaken.\n",
      "     Besides, as I have made up his face, the only men can't escape, for\n",
      "     I have advance in soug ma\n",
      "\n",
      "---\n",
      "\n",
      "When in anything which have been how late I yet her. The fellow    would be with very providental very few monograph\n",
      "     table, but it hurdled better over this,\" said the weather and discolouralt has been a\n",
      "     peculiar, might not imagine that he had been advantageous mere; but why\n",
      "     a surpress, besides the crubbeling manner thad\n",
      "     he has drs, and it would not be here two hard accounts after ve yet putted from pape against the utmost importance,\n",
      "     which had been there, as an uggas brow was travelling ines, so he expect me. I assure you-the message to\n",
      "     awaght have been drank aware, MsM.. D. ADo,\" Insion\n",
      "     that had passed the blood of about Awlands that you should.'\n",
      "\n",
      "     \"See how think you would not have ganes with me for getting him.\"\n",
      "\n",
      "     \"There was no harm in this box\n",
      "     and his further twenty fires and stages which have been very good in excitement under my own line's affairs\n",
      "     when they live business. I would hear sworn by the truth. I made a\n",
      "     word of fear a\n",
      "\n",
      "---\n",
      "\n",
      "discover, that he refused to see\n",
      "     him in an instant he puckered the impression if he tells ussected in London, and our\n",
      "     case,\n",
      "     and you'll give a note which you have it all the truth. I caparation\n",
      "     which was that I could not know, indeed, the charminic thicald over feet\n",
      "     to his life, smooding an holery, blue-eyed men would be\n",
      "     accepted; but he was the flams of their mate up them.\n",
      "     But, seation, up my mon pleasant, since was I owe your sign against her\n",
      "     people. One of your age.\"\n",
      "\n",
      "     Holmes's face came to the tunnel. there are sideways a heavily\n",
      "     stair, three of behind us. Only one\n",
      "     was young I flushed after him and hastly done, what colceived t,\n",
      "     there was a wager,\" report of the God respog Holmes.\n",
      "\n",
      "     \"He approached the dining-room upon the story.\n",
      "\n",
      "     \"Are you someone without vague. I looked back in\n",
      "     me to be Blass Holmes.\n",
      "\n",
      "     \"So far out,\" cried Holmes.\n",
      "\n",
      "     \"What were you?\" he cried in his eyes.\n",
      "\n",
      "     \"Passing gloves, which\n",
      "     could h\n"
     ]
    }
   ],
   "source": [
    "iteration(64,1024,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYxo5xEKRrY7"
   },
   "source": [
    "##128 1024 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1510463,
     "status": "ok",
     "timestamp": 1608318267329,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "Fes8X8L9POOJ",
    "outputId": "7cdfb13c-727a-4d26-ce37-f635b44ccc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (64, None, 128)           12416     \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (64, None, 1024)          3545088   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 3,656,929\n",
      "Trainable params: 3,656,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 32s 57ms/step - loss: 2.7672\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.4820\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.2745\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.1922\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.1474\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.1111\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.0828\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 32s 58ms/step - loss: 1.0600\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 32s 58ms/step - loss: 1.0378\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 31s 58ms/step - loss: 1.0195\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (1, None, 128)            12416     \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (1, None, 1024)           3545088   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 3,656,929\n",
      "Trainable params: 3,656,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes sprang to a hotel.\"\n",
      "\n",
      "     \"This was what the spite of whom?\"\n",
      "\n",
      "     \"Well, not to the beautiful woman in which I used at once as having a cuped, and he spent with\n",
      "     Wallelfied to the each girl. Leave rise a formidable man with his learned valley the chril    very first words and broadened. It was disturbed them a clive following me, human\n",
      "     inquiries and badly coles at our little traces. She things he poured out\n",
      "     almost curiosity. \"I am sorry to be a very like match. The\n",
      "     car spoke in a special siline woman,\n",
      "     has left him up when I left twinel. She has longer with my conduct.\n",
      "     Her fingers gave a man lighting, and yet how she was about to\n",
      "     know what the foggessory of his face was spoken of brdather\n",
      "     open, but the tra qua\n",
      "                  as conveyed to us wasthis panasel, human eyes on which I could make to get me on turn. Anyways\n",
      "     through by the hall doof our third recalls tured to scienting it.\n",
      "     It was about to be formidable that you have \n",
      "\n",
      "---\n",
      "\n",
      "When's\n",
      "     time, but never be caured in time for nervous, but the money called men.\"\n",
      "\n",
      "     The Poor direction that the housekeeper happened to break in\n",
      "     a large revolver. \"I took the best thing in sight of him. Mawhodall bow is he. \"You will be no one has known candle I am asking\n",
      "     Sir Henry. Having served the point of him now know.\"\n",
      "\n",
      "     \"But we can indeed his nervous intentness, and we make no good with\n",
      "     you.\"\n",
      "\n",
      "     TAll Ballar Howells will prevent?\"\n",
      "\n",
      "     \"You certainly observe that laughter is enough to do with the\n",
      "     calculation. Now I'm soon realize that the gleam sad Heaven talked away attacts of a woman.\n",
      "     Even if he had entered the lady's suspense for Mr. Behere I pointed to him. There is any remarkable man tithe. He still made one hand had a kindly fears at organize the\n",
      "     man to ite fore expects. Believit engineer. The face built mad be a\n",
      "     sensities.\"\n",
      "\n",
      "     \"And how do you know this spring-face dressed in a cold snify, shadow employments.\n",
      "     We hide a h\n",
      "\n",
      "---\n",
      "\n",
      "discovery by the whole. A jour and the\n",
      "     cable buy go for a moment, two dreams passing.\n",
      "     Through the printing signal, not to talk off upon us at the door. \"Come. I watched\n",
      "     you should have been present sure enough, and looked like a malmably with\n",
      "     a strange third pluns of paper like this, when a long journey Jones was a\n",
      "     ten-offinential; for or withhe campable of interest to act on the Underground\n",
      "     Europe. It is secret at that moment?\"\n",
      "\n",
      "     \"A town practice for experience in them. Two lovers I on\n",
      "     observed the trick in form when he had possibly thrill\n",
      "     open and already forget it. There is, whether the other\n",
      "\n",
      "     Stanley Hopkins called for Jackmort laughing, square and raise up. My hurry did not\n",
      "     see to me, and waving his eyes, and a-mounted to the door and examined the house which\n",
      "     huntred woods us easily consumed from the door. A husband was\n",
      "     within an alarm and shoots of the silence of bankers instantly,\n",
      "     so he laid the scandall be a mistake, \n"
     ]
    }
   ],
   "source": [
    "iteration(128,1024,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3RpjQcKRnXF"
   },
   "source": [
    "##512 1024 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1905779,
     "status": "ok",
     "timestamp": 1608318662651,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "SKxxBOLqGmPL",
    "outputId": "17c5468d-b172-44f1-a0ea-d720f3364a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (64, None, 512)           49664     \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (64, None, 1024)          4724736   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,873,825\n",
      "Trainable params: 4,873,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 39s 70ms/step - loss: 2.4977\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 38s 70ms/step - loss: 1.4292\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 38s 70ms/step - loss: 1.2568\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 38s 70ms/step - loss: 1.1882\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.1443\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.1140\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.0882\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.0657\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.0477\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 38s 71ms/step - loss: 1.0305\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (1, None, 512)            49664     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (1, None, 1024)           4724736   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,873,825\n",
      "Trainable params: 4,873,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock\n",
      "     \"Lyon--that's whether the matter,\" by the\n",
      "     house, to Ettie St. Life allowing himself.  Yet on earth\n",
      "     suddenly sprung to carrying however, as you are more quarrel,\n",
      "     and frosty sparling, as we knew nothing of my reach, my good faca! Bring it up into\n",
      "     successful proposition, but I am only a during manner before he leaned upon\n",
      "     frightened. My without recall it at that indication.\"\n",
      "\n",
      "     \"Yes, sir; he bicycleisn party that the young lady reads his astonishment, who\n",
      "     wonder which he fled off groan for lighting his results sorted all\n",
      "     in his the sole one who leads her. She knows of a very welche. Yet I am\n",
      "     another people will give my judge, for a factition, and anxious that I inquired\n",
      "     it all to walk.\"\n",
      "\n",
      "     \"And a dankerory?\"\n",
      "\n",
      "     \"What thing?\"\n",
      "\n",
      "     \"I can tell you much. But next?\"\n",
      "\n",
      "     \"No foremost assassin.\"\n",
      "\n",
      "     \"Because I have heard him. I shall be able to it--that is, I though any quivering with\n",
      "     those who answered with escape. There is \n",
      "\n",
      "---\n",
      "\n",
      "Whents.\"\n",
      "\n",
      "     \"But what a  Saturdayly Shall Pacticu, to be already giving you a\n",
      "     day to the very line of ener. His pence, and the criminaly. And the large district had begun I\n",
      "     felt from our furious secretary. Gregson, finally, he became a fale-finger rest,\n",
      "     receive the moor fellow, and so drew out his bord in which I\n",
      "     had dong it. You have done in view of trouble, and I must be\n",
      "     women to the house or complication, and a large number of flattings\n",
      "     which book responsible. There's not yet produck to have been a man again.\"\n",
      "\n",
      "     \"I tractice during Crookers in the Regies of London. Dr. Mortimer,\n",
      "     we all lose does it not for him a candle until we had really come\n",
      "     now of it. It're true yet--we'll find no questions.\"\n",
      "\n",
      "     \"I'm ready to make to say; but he's future, but I had no until we all\n",
      "     engaged and traces from the safe, and I saw him low up and ruefully\n",
      "     and resume the apparribre cease. There's no other\n",
      "     instrusion of Blefter and took to the the\n",
      "\n",
      "---\n",
      "\n",
      "discovering his room he lay behind.\n",
      "\n",
      "     \"The inspector's lonely coroner's suspicion would handle sure  about myself over by time to collect. The readers condrolled when he laughed\n",
      "     into last hand.\n",
      "\n",
      "     \"You've been oxer, but now I couldn't much theatre to do that.\"\n",
      "\n",
      "     \"Tell it a cridicious, Mr. Parlages?\"\n",
      "\n",
      "     The woman are half-ray passage. This lith of some hundreds in as unlikely. Ol, and the\n",
      "     endowed drink and with any use here. Now I guess I want to\n",
      "     go with me furnished. Master looked a little from posses. They had drawn it from an end of the country\n",
      "     lock, candle out of policemen and wondeling as if it would come. I'd reconstruct his bord on eith a great city, and entered\n",
      "     it is distinctive. The bar rose for saying that I had essaulted\n",
      "     until we were, for days I had done so; for havill\n",
      "     begins to discover consuman investigation from Eccles Wilson,\n",
      "     surgeoned in his bedroom against his eyes, and that it would a five\n",
      "     or fator, besides his light \n"
     ]
    }
   ],
   "source": [
    "iteration(512,1024,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LNAnx2aRiW8"
   },
   "source": [
    "##1024 1024 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2402476,
     "status": "ok",
     "timestamp": 1608319159353,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "heWp6BSbPPkf",
    "outputId": "d6c1bd9a-e241-4150-e3a0-3311a586f263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (64, None, 1024)          99328     \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (64, None, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 6,496,353\n",
      "Trainable params: 6,496,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "523/523 [==============================] - 49s 89ms/step - loss: 2.1713\n",
      "Epoch 2/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.2877\n",
      "Epoch 3/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.1819\n",
      "Epoch 4/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.1298\n",
      "Epoch 5/10\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.0955\n",
      "Epoch 6/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0690\n",
      "Epoch 7/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0453\n",
      "Epoch 8/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0255\n",
      "Epoch 9/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0089\n",
      "Epoch 10/10\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9937\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (1, None, 1024)           99328     \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (1, None, 1024)           6297600   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 6,496,353\n",
      "Trainable params: 6,496,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes. \"We'll all this, but he is\n",
      "     in the miscons only this starting-powerful miners--is--\"\n",
      "\n",
      "     \"But I cannot peculiar such an iron-grap of your sins are\n",
      "     theyefice with information, and Gennaro was that in the Higa follow out from\n",
      "     South Africa.\"\n",
      "\n",
      "     Holmes's report to me. I have said my companion. \"We will\n",
      "     appear to your help to your study. Then, Watson, for I insist upon ourselves in\n",
      "     trudge to publishicaping-room? What news or teeth limselves to fid in the police; but his smile\n",
      "     clean enough that it was damped across the\n",
      "     garden. At it may be her. It would not help into my\n",
      "     treasure.\n",
      "\n",
      "\n",
      "    h the wevered hypothesis, and\n",
      "     came some tenants or, a man of peds. The expert sounds at the head, lump and\n",
      "     discretion, but Holmes had been communicative. I don't think that I thought he knew that the\n",
      "     chief hung a day shilling of a tall myself. He would have warned the secret\n",
      "     weeks before him.\"\n",
      "\n",
      "     \"It at that moment that they have elsem\n",
      "\n",
      "---\n",
      "\n",
      "When the morning he\n",
      "     suspected. There must be he he saw something\n",
      "     of out from a body.\n",
      "\n",
      "     \"There is no great longer before had been dead,\n",
      "     and looked at my ears had been do no word in the burding. Oted\n",
      "     before he glanced round the sunk bullet's room which was the\n",
      "     highorote moon wandered with his household. He\n",
      "   has been entirely promise to ensu    entered\n",
      "     to his method. He was again, until he had wast a funntal thread by overthen, but it seems two more singular disease\n",
      "     founded up above them, and the cadicardly because he always have expected. The word was\n",
      "     that he would like to be on the winterview, and the man himself\n",
      "     were ending. It was something of the man at 100. The\n",
      "     1030 and towely to represent my irresual in the\n",
      "     minutes, and then I came from the street. They are both eyes,\n",
      "     when they turned across his hand. Our dy stopped vile that evening all he has offered him then.\n",
      "     He is a\n",
      "     trusty conscious one. These little made m\n",
      "\n",
      "---\n",
      "\n",
      "discovery entrusive\n",
      "     criminal.\"\n",
      "\n",
      "     \"Under that last dinner was dead,\"\n",
      "\n",
      "     \"And Then the note was beyond impartive.\"\n",
      "\n",
      "     \"Yesterday?\"\n",
      "\n",
      "     \"In a youth with a first-class tide in twenty tyles' in the shouldeying! He is still patiently frequences,\" said Holmes, in the\n",
      "     fored board of the door.\n",
      "\n",
      "     \"Well, well,' said I.\n",
      "\n",
      "     \"'Oh, it all cheer after this message which vanished\n",
      "     in the English detective; \"but, too, and I am syirit--an injustionate thousand to bring his whole life\n",
      "     in factor.\"\n",
      "\n",
      "     The strangerous deuger, through the halt which were too detachment, and see\n",
      "     was tracked and sorrow to seeking. They had been estim, which he\n",
      "     appeared arreet of a ready startled across the moat for many a long busts still\n",
      "     off in winter-Arrest day's whole lebtere by certain this\n",
      "     beyond yourself, where we can tell us the glint all\n",
      "     of the money, and I will tell my circulation. \"That's the news a\n",
      "     wound and of little will excuse myself and in some contim\n"
     ]
    }
   ],
   "source": [
    "iteration(1024,1024,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YjY25DBN04T"
   },
   "source": [
    "#Epoch Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAzH2W03TAtw"
   },
   "source": [
    "##256 1024 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2581206,
     "status": "ok",
     "timestamp": 1608319338089,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "zxqkM6NrTAbO",
    "outputId": "0e7e9edd-c692-45e7-fe01-bed005ed3299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "523/523 [==============================] - 34s 60ms/step - loss: 2.6004\n",
      "Epoch 2/5\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4282\n",
      "Epoch 3/5\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.2517\n",
      "Epoch 4/5\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1792\n",
      "Epoch 5/5\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1361\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes\n",
      "     that sixtens that the singular and discharging for me in which\n",
      "     forehe has been\n",
      "     fixed tift. But, it so that we could upen the roofs, coming\n",
      "     for yonders. Look how record in seal that has\n",
      "     been twisted in a corner with a prigate journey.\"\n",
      "\n",
      "     \"A sail, excitement case.\"\n",
      "\n",
      "     \"My dear sir?\" cried the trees, scraphed relations. At last te man side and\n",
      "     rap down Aldgrard--who came glancing eye was reproaty. Here died\n",
      "     Africa in the inspector, when I sway of burst from the kindly strike hundreds which mystery\n",
      "     each of the opportunity. It was not survice\n",
      "     gone. He had no other woman's dislike or wishes,\n",
      "     and being to go to think that theyse propressed in the man as he handed Pan would not say\n",
      "     he would be of it. You are now resture to a plans!\" he cried.\n",
      "\n",
      "     \"Halloa! Was possibly think that it would have suspiced that he\n",
      "     gave bit when they are to certainly dapense than to a finish fright. Then I walked so excited in the way of a \n",
      "\n",
      "---\n",
      "\n",
      "When they\n",
      "     discorners\n",
      "     which had been speens. A decept sigh you have given the whole thunger off.\n",
      "     The man must have sat up our door?\"\n",
      "\n",
      "     \"That was it so possible a man, Watson, but there is someone him, An his oponess, beornature\n",
      "     two in my own position to Stery and Pare observed, a foreigner\n",
      "     than them off before we were not our principaties. \"Any\n",
      "     vanished, 6ath.\"\n",
      "\n",
      "     \"And to find a very point of some opin?\"\n",
      "\n",
      "     \"No, Mr. Holmes,\"\n",
      "     said The gallen separation.\n",
      "\n",
      "     \"Anyhow's would be guliard, Moriarty! I beg you what they have almest\n",
      "     all proper; the very impossibility of\n",
      "     many or neither we shall be settly one. I am not upon the murderer\n",
      "     that he had\n",
      "     muscuiters, trieded the corner of no help you will help to return from my\n",
      "     hat a Hunter &\n",
      "     then,\n",
      "     with poor Lord Treding On the situation of the pethology against the adviser behind the\n",
      "     charge as after I counted fast away, then, you would induch your\n",
      "     visitor, she answ\n",
      "\n",
      "---\n",
      "\n",
      "discovered hempt.\n",
      "   hice, wish. We will do buy there is an angle of life. It must have been\n",
      "     remarkable benuful miles and I excreet.\"\n",
      "\n",
      "     \"That is possibly canisuoine.\n",
      "\n",
      "     But he has a search coming\n",
      "     leaving, who, walked half-day ever more long, presentamily, with rest?\"\n",
      "\n",
      "     \"No, you'll have former message to only to come into the deep\n",
      "     on the letters which we escape upon them. 'While\n",
      "     I have drifved by his their open. The mere said at\n",
      "     butler coming against\n",
      "     sort, nor contrm of he was\n",
      "     quite deep-coloured athat three way. He whistled\n",
      "     between Norwica.'\n",
      "\n",
      "     the light sat no plans.\"\n",
      "\n",
      "     He has kept persuading so many that set in\n",
      "     where his white face that good thon he could\n",
      "     get ous that he had into a hour to case he could not be published you with\n",
      "     importance very popularity. It would be, however, as your pursuis. He is\n",
      "     about the most love in my connouncious two of his death be objects in it, but\n",
      "     still e wife when he could not ge\n"
     ]
    }
   ],
   "source": [
    "iteration(256,1024,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8sIIQ7KS6xC"
   },
   "source": [
    "##256 1024 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3247880,
     "status": "ok",
     "timestamp": 1608320004770,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "sTa4KMjPH9_2",
    "outputId": "98f81096-1b28-428b-8ecf-8b73809c4c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "523/523 [==============================] - 34s 60ms/step - loss: 2.6359\n",
      "Epoch 2/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4205\n",
      "Epoch 3/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.2441\n",
      "Epoch 4/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1754\n",
      "Epoch 5/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1309\n",
      "Epoch 6/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0970\n",
      "Epoch 7/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0713\n",
      "Epoch 8/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0482\n",
      "Epoch 9/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0265\n",
      "Epoch 10/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.0094\n",
      "Epoch 11/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9928\n",
      "Epoch 12/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9768\n",
      "Epoch 13/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9633\n",
      "Epoch 14/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9518\n",
      "Epoch 15/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9422\n",
      "Epoch 16/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9333\n",
      "Epoch 17/20\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9262\n",
      "Epoch 18/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9214\n",
      "Epoch 19/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9180\n",
      "Epoch 20/20\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9152\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes are\n",
      "     in an hour's surrounding the Herequates one miles off to show the\n",
      "     meantime to secruct the second night, and so had thr us so dark to arouse with him, while we warn altogether--for tennight had they\n",
      "     suffer of neathe more descend. I\n",
      "     watch with her when he raised her onws for them, do the post, the clue it not been\n",
      "     in the habit of summit, but aquil my belief that during their plains who had\n",
      "     not advanced whistless, after I handed my returning novel was done, and he\n",
      "     had been patience back with him--that my messages Watson, the\n",
      "     acquaintance of the very hour opens any illfully.\"\n",
      "\n",
      "     \"You mean to that. Hold Alexandre was not mere change.\n",
      "     Nothing in it.\"\n",
      "\n",
      "     \"But what has attain? You have a great murder of the beg your supering the\n",
      "     will give a coupination?\"\n",
      "\n",
      "     \"I'm proud to say! What did he not be used to overtaken under.\"\n",
      "\n",
      "     \"My dear Watson,\" said he, pointing on to the times with which the low, cloudy moulds window as\n",
      "   \n",
      "\n",
      "---\n",
      "\n",
      "When I see that I, who did it, and I\n",
      "     reached them every day to the rest as the capture. Books were speech at his\n",
      "     way already in his position.\n",
      "\n",
      "     \"What, that's the mornings of the life less.\n",
      "     Luctor last night, at the door of the sideboard, which made no\n",
      "     more than the such visitor on The DeadilGthey's dearest to\n",
      "     the kingdom of the road, when every nd with the intention of One work\n",
      "     were stepping up the car.\n",
      "     There was a convulation in my road. It was not nearly everything after\n",
      "     mistran a folk in the somnow of our orderly house, that u shall I like to keep the property\n",
      "     outside the direction to this American station. It has deserted his ceiling within\n",
      "     her last top piece. \"Ah, it didn't do bettered\n",
      "     it for, and he did not tell them then, without anyone my notes, and\n",
      "     the places were some time before to do with him. He had vanished hard-hunge I only\n",
      "     knows, however, and of country had just quitted. One human like\n",
      "     enholds with a\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "discovery were turned in\n",
      "     someone who came struck him in the arm-chair, and the tufted\n",
      "     hours in this chair and the lady. \"My word, impossible!\"\n",
      "\n",
      "     In reasoning, she had a copy of us set rising and disaster, and I am by expectation the\n",
      "     Holmes's eyes before my life. There was no chance for the arresting habits, and it was head, a broken blackmailed method\n",
      "     at up with my power over. Lying of importance it will be more intently\n",
      "     disclosed and kissed the smoke by perfect conclusion that he had seen upon the\n",
      "     achold day of one of the starts and had lost her.\n",
      "\n",
      "     \"I am so unpleasang. Yes, it was unseen. I admorally destroyed it,\n",
      "     and all the tragedy arrived?\"\n",
      "\n",
      "     \"Personally it would his wife with Douglas and three miners. I lay it about over\n",
      "     myself. I have no doubt at all. I drew ills with you, his\n",
      "     lens, the best of residence in the darkness, one blow do nothing on a\n",
      "     princely scare at the door of the light. Nothing often were\n",
      "     risen. If the\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "iteration(256,1024,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA36kb4gS0zA"
   },
   "source": [
    "##256 1024 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4238803,
     "status": "ok",
     "timestamp": 1608320995698,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "oprjFyqsJsid",
    "outputId": "69c090b2-af2b-4e97-c7b8-19232fe290fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "523/523 [==============================] - 34s 60ms/step - loss: 2.6191\n",
      "Epoch 2/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4280\n",
      "Epoch 3/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2491\n",
      "Epoch 4/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1771\n",
      "Epoch 5/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1340\n",
      "Epoch 6/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1006\n",
      "Epoch 7/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0752\n",
      "Epoch 8/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0523\n",
      "Epoch 9/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0310\n",
      "Epoch 10/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0139\n",
      "Epoch 11/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9975\n",
      "Epoch 12/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9845\n",
      "Epoch 13/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9714\n",
      "Epoch 14/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9589\n",
      "Epoch 15/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9491\n",
      "Epoch 16/30\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9401\n",
      "Epoch 17/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9341\n",
      "Epoch 18/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9286\n",
      "Epoch 19/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9230\n",
      "Epoch 20/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9203\n",
      "Epoch 21/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9185\n",
      "Epoch 22/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9158\n",
      "Epoch 23/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9173\n",
      "Epoch 24/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9166\n",
      "Epoch 25/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9179\n",
      "Epoch 26/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9199\n",
      "Epoch 27/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9217\n",
      "Epoch 28/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9256\n",
      "Epoch 29/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9284\n",
      "Epoch 30/30\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9341\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes was closing\n",
      "     to my mind. Peters--the grounds and the warmant came to the window-sill talk about silk.\"\n",
      "     There came her into get as much of the Daily bird.\n",
      "\n",
      "     \"About that?\"\n",
      "\n",
      "     A door of the shutters. Then who were daring giarly complete bonds?\"\n",
      "\n",
      "     \"Yes, that was dreadful to me for the thing was\n",
      "     really very clear reason to you against the gase of the\n",
      "     inconjection of this desperate talk. His brows\n",
      "     was pure seven been oped from the head weeks of his low, but over\n",
      "     we came out and lunch a murder interest and yet has save interest in\n",
      "     my hair in opinion that my friend Dr. Mortimer seem to drive away in the\n",
      "     paper. There is no silnimple refully found three souse up everything in\n",
      "     my mind or remark, the result which should be the same estimate messenger.\n",
      "\n",
      "     \"You will chall think it there after describe that's for ten minutes if I were to come\n",
      "     at once; but if anytogething you will see little of\n",
      "     itmeet nor which ran call to thi\n",
      "\n",
      "---\n",
      "\n",
      "When I may take it to the\n",
      "     male\n",
      "     healows, a breast-rooms which was married under the evening which\n",
      "     had farled with the\n",
      "     ight, for his wife has given hear some great steepen it again; and yet he was so far\n",
      "     together. Hudson has been mad upon us for an alternative that in\n",
      "     yeat Birlst the law.\"\n",
      "\n",
      "     Holmes should pass later to our investigation itself; but\n",
      "     only an instant he pointed to the garden.\n",
      "\n",
      "     \"The shoe-clected half of his mind will it be more likely?\"\n",
      "\n",
      "     \"The case came to Baskerville Hall for som an assurement, Mr. Holmes.\n",
      "     Agra, then, how on earth, I have nothing to do with his eyes.\"\n",
      "\n",
      "     \"Is it the slip?\" said he together in the subject.\"\n",
      "\n",
      "     The let it have put it down.\"\n",
      "\n",
      "     Blair false slips are injent fire. A bearie cried along until it was followed by an\n",
      "     open door just before us. In the cebthad was a complain\n",
      "     observant attention to him.\"\n",
      "\n",
      "     I brought me from his notebook, but a gleam of a high\n",
      "     house began to come \n",
      "\n",
      "---\n",
      "\n",
      "discover, been specially at work at 7 before we can only be from his\n",
      "     sleeves. Let him look upon me the work has come of it a quarter of an honest\n",
      "     murder again!\"\n",
      "\n",
      "     \"Who is your with satisfied me--ever a thin has he. It is true.\"\n",
      "\n",
      "     \"Myectitiface,\" said I, tunnial. All that the\n",
      "     hills of a quarter of a mine or an injured country preciping at once the floor\n",
      "     leadhing very mere so\n",
      "     exceptional relatives of the shot. The bullets of every night, if my name is Firbus the death could be\n",
      "     wondered with timis with people dog-matter.\"\n",
      "\n",
      "     \"You see, at his excellent sequence hung from the three.\n",
      "\n",
      "     \"You know what I did, this man Peter Carey, had been shot half out on the losp, saw\n",
      "     there will became round on Mrs. Cecil Furither, and, as I have had\n",
      "     most news.\"\n",
      "\n",
      "     \"There's no doubte of ever drove upon all the writing in an angle and\n",
      "     rose from the scener was known moboled on those excitement at the treal to attach.  He\n",
      "     heard a minute looking for wai\n"
     ]
    }
   ],
   "source": [
    "iteration(256,1024,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS6YiZX-SyA8"
   },
   "source": [
    "##256 1024 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5551140,
     "status": "ok",
     "timestamp": 1608322308041,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "euA0SR3ILHWq",
    "outputId": "d111015a-1490-462e-fa8b-29c440049460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 2.6119\n",
      "Epoch 2/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4319\n",
      "Epoch 3/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2524\n",
      "Epoch 4/40\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 1.1816\n",
      "Epoch 5/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1384\n",
      "Epoch 6/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1047\n",
      "Epoch 7/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0796\n",
      "Epoch 8/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0568\n",
      "Epoch 9/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0377\n",
      "Epoch 10/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0191\n",
      "Epoch 11/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0031\n",
      "Epoch 12/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9887\n",
      "Epoch 13/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9747\n",
      "Epoch 14/40\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9615\n",
      "Epoch 15/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9534\n",
      "Epoch 16/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9446\n",
      "Epoch 17/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9365\n",
      "Epoch 18/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9312\n",
      "Epoch 19/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9265\n",
      "Epoch 20/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9232\n",
      "Epoch 21/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9207\n",
      "Epoch 22/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9180\n",
      "Epoch 23/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9186\n",
      "Epoch 24/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9172\n",
      "Epoch 25/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9165\n",
      "Epoch 26/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9204\n",
      "Epoch 27/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9211\n",
      "Epoch 28/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9237\n",
      "Epoch 29/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9279\n",
      "Epoch 30/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9333\n",
      "Epoch 31/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9382\n",
      "Epoch 32/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9405\n",
      "Epoch 33/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9464\n",
      "Epoch 34/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9534\n",
      "Epoch 35/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9616\n",
      "Epoch 36/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9721\n",
      "Epoch 37/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9812\n",
      "Epoch 38/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9891\n",
      "Epoch 39/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0021\n",
      "Epoch 40/40\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0180\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock Holmes.\n",
      "     The man with a room by he stulfulsher with results. His brow with him a cash away day that\n",
      "     the mass movements and good? Taken in my power, and very givin\n",
      "     expecta was our criminals who heard that he was to leand so rapid to\n",
      "     St. Cluster Baskerville Hall, with sanner and examined\n",
      "     intently.\n",
      "\n",
      "     \"I wonder that you have a mercy of a young man.\n",
      "\n",
      "     \"Sir Eurwoiland Wood, law came to thought an\n",
      "     inn out of the Kepail.\"\n",
      "\n",
      "     \"What thing the facts around improsesment?\"\n",
      "\n",
      "     \"Who---she buried in your trouble?\" said McGinty rossed the\n",
      "     spring to Miss Morton, who has not been searched. My only now. He opened the\n",
      "     tobacy--and we walked it on each and\n",
      "     togetue,\" and Vitton Shafter, with ghistle investering emotion. For five\n",
      "     Huntabolple seemed to be a permit unlightens day for\n",
      "     and be at the same to my room.\"\n",
      "\n",
      "     The acquaintance of Barrymore run such a difference to cock at the bottom\n",
      "     above my throat.\n",
      "\n",
      "     \"He arrested. I\n",
      "     co\n",
      "\n",
      "---\n",
      "\n",
      "When they are in\n",
      "     other gentlemen.\"\n",
      "\n",
      "     The road was a black sudden and most mate as recognise as I was to line, and I\n",
      "     felt that he was a young empnooner together as if in portiofmental\n",
      "     Eucoral had left the door by Jacob Mr. Small. The worth\n",
      "     management, and a beautid  they belondly. Then we shall, here is he Trevords, a cryadep arm. Slowly it\n",
      "     impediformanyou will excuse myself.\" He put me gringing neighbours\n",
      "     Bylines.\"\n",
      "\n",
      "     \"Well, I also gived me to searn the Door for the lividette. I left its and\n",
      "     complexion will be glad to preceal. But your presence is\n",
      "     almost inch came to you, Egable!\" McMurdo said constable.\n",
      "\n",
      "     \"The two dozen: I often wastened you forget that I shall\n",
      "     all in the distant of the day, have the appurre?'\n",
      "\n",
      "     \"I will see that if I falls!\" I exclaimed.\n",
      "\n",
      "     Hich a train was the simplicity little and pursuet\n",
      "     lunch the time, and it is my back at you down there but the\n",
      "     suffer which lay befable, and he was dressed behind\n",
      "\n",
      "---\n",
      "\n",
      "discovered?\"\n",
      "\n",
      "     The inscrutiness will carry out our heap of a second the same fancy to that last deed\n",
      "     and interesting glance. He was a Sman times under the mire. But, and another\n",
      "     that he has sufeized and she stood half words eagerly over the mais. \"In he can take a crowns of and life in the society-of--only\n",
      "     you were alone and distonce, and were tyle to show you that he showed\n",
      "     my easy going cruster you would come for unnecessay to me.\" \n",
      "\n",
      "     \"Yes, he was paced of buffast, and do join?\"\n",
      "\n",
      "     \"I have no doubt that principle that it was Standardal.\"\n",
      "\n",
      "     \"Our creet was as when I suggested.\"\n",
      "\n",
      "     \"Anything else in my advantage.\"\n",
      "\n",
      "     Holmes asked me did. But I can't get call advice that I\n",
      "     may be muffled agid to the eye from their eyes.\n",
      "\n",
      "     \"My name are injuries one in a week-ent or at all?\"\n",
      "\n",
      "     \"He in the first shadow's client. Our whole office! That is well\n",
      "     undisturbed.\"\n",
      "\n",
      "     Baskerville    was prin upon the floor. The\n",
      "     large could contract with an eq\n"
     ]
    }
   ],
   "source": [
    "iteration(256,1024,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sg-JemD_U1CQ"
   },
   "source": [
    "##256 1024 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7188206,
     "status": "ok",
     "timestamp": 1608323945113,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "cWd__GcGNDLU",
    "outputId": "fe1d0e0c-4cef-4f70-d9d6-17cd25097764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (64, None, 256)           24832     \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 2.6322\n",
      "Epoch 2/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.4288\n",
      "Epoch 3/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2487\n",
      "Epoch 4/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1777\n",
      "Epoch 5/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1341\n",
      "Epoch 6/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1029\n",
      "Epoch 7/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0758\n",
      "Epoch 8/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0520\n",
      "Epoch 9/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0331\n",
      "Epoch 10/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0149\n",
      "Epoch 11/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9983\n",
      "Epoch 12/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9825\n",
      "Epoch 13/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9706\n",
      "Epoch 14/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9589\n",
      "Epoch 15/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9483\n",
      "Epoch 16/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9399\n",
      "Epoch 17/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9333\n",
      "Epoch 18/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9286\n",
      "Epoch 19/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9221\n",
      "Epoch 20/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9196\n",
      "Epoch 21/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9165\n",
      "Epoch 22/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9163\n",
      "Epoch 23/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9147\n",
      "Epoch 24/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9164\n",
      "Epoch 25/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9169\n",
      "Epoch 26/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9171\n",
      "Epoch 27/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9224\n",
      "Epoch 28/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9247\n",
      "Epoch 29/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9278\n",
      "Epoch 30/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9331\n",
      "Epoch 31/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9382\n",
      "Epoch 32/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9440\n",
      "Epoch 33/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9494\n",
      "Epoch 34/50\n",
      "523/523 [==============================] - 33s 60ms/step - loss: 0.9567\n",
      "Epoch 35/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9663\n",
      "Epoch 36/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9767\n",
      "Epoch 37/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 0.9845\n",
      "Epoch 38/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0011\n",
      "Epoch 39/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0106\n",
      "Epoch 40/50\n",
      "523/523 [==============================] - 33s 61ms/step - loss: 1.0222\n",
      "Epoch 41/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0333\n",
      "Epoch 42/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0418\n",
      "Epoch 43/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.0601\n",
      "Epoch 44/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1004\n",
      "Epoch 45/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1312\n",
      "Epoch 46/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.1938\n",
      "Epoch 47/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2442\n",
      "Epoch 48/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2228\n",
      "Epoch 49/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2173\n",
      "Epoch 50/50\n",
      "523/523 [==============================] - 32s 60ms/step - loss: 1.2348\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (1, None, 256)            24832     \n",
      "_________________________________________________________________\n",
      "gru_27 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 4,062,561\n",
      "Trainable params: 4,062,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock it\n",
      "     of Niveredrinent it.\"\n",
      "\n",
      "     \"The cand was a very like, but in we gaze in\n",
      "     the suce malactrapse was end. It was at missed chill of\n",
      "     their dead safe, and I will unders for this ison the diniefartition, \"before,\n",
      "     Whot Mr. Holmes.\"\n",
      "\n",
      "     \"Yes, I waiting fishish, ank I am if you are\n",
      "     deat-ginnourr.\"\n",
      "\n",
      "     'Comin Stapleon. \"Wasic was it up, Mr. Holmes. \"Yes, sir.\"\n",
      "\n",
      "     \"We can be said not? She ganged an inst and given, stinging\n",
      "     the words locked. Smanly ushed he examined the usaintimes in his line, but portious every\n",
      "     friends turn down, you know that, Watson, you see his emotion to\n",
      "     the elters. In the Indead Holmes could never keep your gincy as\n",
      "     impost Still. Stain!\" she said me his own\n",
      "     close of hills and put ins quite forature. It's wry not beast.\"\n",
      "\n",
      "     The bartering out of Bots England, who can see, Misor Convictise, to stoke to as Drebbed and surely at my streebstair my\n",
      "     escapion so disere was in my sisteriatoly.\"\n",
      "\n",
      "     Curlegro gens pr\n",
      "\n",
      "---\n",
      "\n",
      "When there in this came he\n",
      "     curries are certainly, and the window, but this ness in the\n",
      "     police case before night shiller lean face. In the cives of whips that took faron or a very sinion fire to scrate and a gie\n",
      "     was seen hard figure. It is unally, Wearling that he shall see if the\n",
      "     course famons should turnoned any stove; but it\n",
      "     Watson. You can oner to you, Mr. Holmes? But I have\n",
      "     men in insen, and to be concilenter. Then teremarcy nor there, Lancas had\n",
      "     as he gave any keeper hour great lither had done know occurred\n",
      "     saw it\n",
      "     of Cried Holmes.\n",
      "\n",
      "     Not very liem they above\n",
      "     in an earson in her waiting fortune yabos. My dear features got the\n",
      "     over o'clock of his hand.\"\n",
      "\n",
      "     the treach. That may the same deavle imeritical schore sides throw\n",
      "     to may he, in his Hote and were stare. There were sorrinderent. The smeet was he seemed in a mothough.\"\n",
      "\n",
      "     \"The Markin, I canseton?\" he.\"\n",
      "\n",
      "     She was are neither an ad nature he was so\n",
      "     disarred\n",
      "\n",
      "---\n",
      "\n",
      "discover, matter for that in Ammstrain notice\n",
      "     would all the tall.\"\n",
      "\n",
      "     with a face and streeped questioned. The same insome was and catrale, \"from whact had seen fair-planted up inn ordations\n",
      "     punched anyone.\n",
      "\n",
      "     \"I have hons we should have you truet the only\n",
      "     simple.\n",
      "\n",
      "     \"It's not the acted mattering of the native men have inediant on the square.\"\n",
      "     Sherlock Holmes small kept ran uptomitions to our than\n",
      "     into his feet denortant. He was in them ivalson,\"  Thankma,\" he fancted to meet as evened, on the man who spoke you.\"\n",
      "\n",
      "     THE Scottland monthsprine that the marridgenceed\n",
      "     to-night he was inday and remarkable visit to the\n",
      "     forlow hard. The one box was near times, though, itself\n",
      "     the matter of he white it was in her ladison, for Here deep-master's arms, when\n",
      "     would he pous the pilion it--might have add drives!\n",
      "     sorely we keep at them tenory to reash upon us he may\n",
      "     not certainly in any few piles. Have you have\n",
      "     imposent thesionary that Da\n"
     ]
    }
   ],
   "source": [
    "iteration(256,1024,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aM82GTBBY9wx"
   },
   "source": [
    "## MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9116345,
     "status": "ok",
     "timestamp": 1608325873261,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "57ob-jn0U5XW",
    "outputId": "237bdd3d-762a-4294-ce4d-41b08625388c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (64, None, 1024)          99328     \n",
      "_________________________________________________________________\n",
      "gru_28 (GRU)                 (64, None, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (64, None, 97)            99425     \n",
      "=================================================================\n",
      "Total params: 6,496,353\n",
      "Trainable params: 6,496,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "523/523 [==============================] - 49s 89ms/step - loss: 2.0714\n",
      "Epoch 2/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 1.2657\n",
      "Epoch 3/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.1708\n",
      "Epoch 4/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 1.1244\n",
      "Epoch 5/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 1.0924\n",
      "Epoch 6/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.0654\n",
      "Epoch 7/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.0436\n",
      "Epoch 8/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 1.0254\n",
      "Epoch 9/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 1.0102\n",
      "Epoch 10/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9964\n",
      "Epoch 11/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9852\n",
      "Epoch 12/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9737\n",
      "Epoch 13/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9657\n",
      "Epoch 14/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9576\n",
      "Epoch 15/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9514\n",
      "Epoch 16/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9470\n",
      "Epoch 17/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 0.9428\n",
      "Epoch 18/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 0.9399\n",
      "Epoch 19/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 0.9380\n",
      "Epoch 20/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9368\n",
      "Epoch 21/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9359\n",
      "Epoch 22/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 0.9373\n",
      "Epoch 23/40\n",
      "523/523 [==============================] - 47s 89ms/step - loss: 0.9381\n",
      "Epoch 24/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9416\n",
      "Epoch 25/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9446\n",
      "Epoch 26/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9491\n",
      "Epoch 27/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9512\n",
      "Epoch 28/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9571\n",
      "Epoch 29/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9635\n",
      "Epoch 30/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9723\n",
      "Epoch 31/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9823\n",
      "Epoch 32/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 0.9925\n",
      "Epoch 33/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0011\n",
      "Epoch 34/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0139\n",
      "Epoch 35/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.0341\n",
      "Epoch 36/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.0568\n",
      "Epoch 37/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.0625\n",
      "Epoch 38/40\n",
      "523/523 [==============================] - 48s 90ms/step - loss: 1.1470\n",
      "Epoch 39/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.1939\n",
      "Epoch 40/40\n",
      "523/523 [==============================] - 48s 89ms/step - loss: 1.7466\n",
      "\n",
      "---\n",
      "\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (1, None, 1024)           99328     \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (1, None, 1024)           6297600   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (1, None, 97)             99425     \n",
      "=================================================================\n",
      "Total params: 6,496,353\n",
      "Trainable params: 6,496,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sherlock up. The sold my pop lemy just. dest. a\n",
      "       \"Fou dway you gead shere nter away. Iand s\n",
      " log may nows, \"Well, he an Ame, \"I well blandis bot a whind saveent eviends with any Ase andinguI sater a mind whe rave urn whound lont o sensed was Josemnere arch had lee's deen Braty heree sped in\n",
      "      curn?\n",
      "     is of wift he wnr she wim hister y ath by the mosect thth ruth upon sactuted he litis a oof min youre in the somest.\"\n",
      "\n",
      "        \"Yo whicas, wilk   clemnnistance thomb the savelf. \"You have have just a\n",
      "     in the facen llt ther Ar. Llingt for.\n",
      "\n",
      "       y vescally as e must thened. Theart,\n",
      "        in straugh the spanted, and\n",
      "      an\n",
      "    thing in addsion, seucone reepecateden by\n",
      "       in coolmer I armrses to\n",
      "     The elevapion to lectlat do not,,,\" ssall the\n",
      "     be had burn muld. \"I. Thale sounillyed ourd lives,\n",
      "      nonting-the aiminel gos and dearungtiralnty, and heepord placteand dady e\n",
      "     the paper?\"\n",
      "\n",
      "           \"Younggg in the varviculy prtice all Sire was mork. The charll wod \n",
      "\n",
      "---\n",
      "\n",
      "When I ompertial at fly theree istore.\"\n",
      "\n",
      "      \"Oh, Ame at thear wim yer the Amusty and claurne the\n",
      "   cose. Then I harde adsin them whintw it!' newite claperg talked the martily framerrearbadm.\"\n",
      "\n",
      "    \"Wevervient.\"\n",
      "\n",
      "       and Hise.\"\n",
      "\n",
      "      \"Hes serven your mere in inft men wass of Spimed,\"\n",
      "\n",
      "    \"N,\" ave your to suvere hand\n",
      "    s like trough?\"\n",
      "   at the hard be friould befare it them.\"\n",
      "\n",
      "    \"Theren!, the asqe my reabtasting-!\" I halinngle of\n",
      "      that you doon,\"\n",
      "\n",
      "      \"Ne the that thantm,genevery sool, a trishouled backne the has noll ne exe has butcle compice. But litty, clied, Butet the me pot a.\"\n",
      "\n",
      "    Heabltiot has comes?\"\n",
      "\n",
      "        I courfr:--s wille ond to an haf st your wance an will yout rand\n",
      "   y cere to that your ine. the the blaled a\n",
      "       found ments. Holmes, to thine\n",
      "   y oure ningeservivhed\n",
      "   whonce wabloors have usboore anduschinglol cour\n",
      "  parwse, and\n",
      "     whe do fillt of hink oumplains Vien yer. I lust es has\n",
      "    magrewingo a to the Yan at have\n",
      "     lavinger then who dri\n",
      "\n",
      "---\n",
      "\n",
      "discovery saind dows, with\n",
      " h the fanteray a\n",
      "   wercamszonty sracreses of\n",
      "     then lused glay burgh!\" he baby  tore very sun\n",
      "    Dr.. Itinge that usted and he bas me a\n",
      "      there hereer which larpisher\n",
      " wass which and cerrave. That on and thir\n",
      "     lirt---al waitnce. Than the could\n",
      "  your poahin tou chrines. \"    note by hie the wored sor yon'ted tholgentondswread yout reas As came andand I fusticat of the lircledow he\n",
      "    face ad hurfl\n",
      "     bucandreakne that the not beirf upown teet stone.\"\n",
      "\n",
      "\n",
      "      \"Baten w--g?\"\n",
      "\n",
      "    \"A d with my plawre,\" seanchatt, from I know the\n",
      "      of thoned herwas he andrube, and fromorger? WhLe jejoorrsoothich Dornes twe whic I himad.y the donted.\n",
      "\n",
      "    \"Hopeth the?\"\n",
      "\n",
      "    \"I welike so.\"\n",
      "\n",
      "    ushimpearter for my weve pron preang. I'villed, and of the pose were hime othery ant Dacr, youndly. \"I'll fentled tell we you drest infor the ok the blefrat whell of her at the blory linds\n",
      "     lippt his cupp he glan facy, exply. It am sander that th prefficir\n",
      "     myour frand th\n"
     ]
    }
   ],
   "source": [
    "iteration(1024,1024,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 9116340,
     "status": "ok",
     "timestamp": 1608325873262,
     "user": {
      "displayName": "Derek So",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjU3rwy1FfSIUsFQhL1uGNuwz-Pg2is5QOTG8WK=s64",
      "userId": "10041677120422854144"
     },
     "user_tz": 480
    },
    "id": "96JZ1BWfZFIz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOxTdSivSBHOCt/+PKzpkkx",
   "collapsed_sections": [],
   "name": "charnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
